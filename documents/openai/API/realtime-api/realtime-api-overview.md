# Realtime API

Build low-latency, multi-modal experiences with the Realtime API.

The OpenAI Realtime API enables you to build low-latency, multi-modal conversational experiences with [expressive voice-enabled models](/docs/models#gpt-4o-realtime). These models support realtime text and audio inputs and outputs, voice activation detection, function calling, and much more.

The Realtime API uses GPT-4o and GPT-4o-mini models with additional capabilities to support realtime interactions. The most recent model snapshots for each can be referenced by:

*   `gpt-4o-realtime-preview-2024-12-17`
*   `gpt-4o-mini-realtime-preview-2024-12-17`

Dated model snapshot IDs and more information can be found on the [models page here](/docs/models#gpt-4o-realtime).

Partner integrations
--------------------

Check out these partner integrations, which use the Realtime API in frontend applications and telephony use cases.

[LiveKit integration guide - How to use the Realtime API with LiveKit's WebRTC infrastructure.](https://docs.livekit.io/agents/openai/overview/)

[Twilio integration guide - Buile Realtime apps using Twilio's powerful voice APIs.](https://www.twilio.com/en-us/blog/twilio-openai-realtime-api-launch-integration)

[Agora integration quickstart - How to integrate Agora's real-time audio communication capabilities with the Realtime API.](https://docs.agora.io/en/open-ai-integration/get-started/quickstart)